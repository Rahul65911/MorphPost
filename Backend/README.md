# MorphPost Backend

AI-powered multi-platform content creation and publishing system built with **FastAPI** and **LangGraph**.

## üèóÔ∏è Architecture Overview

MorphPost uses a **LangGraph-based workflow engine** to orchestrate AI content generation, evaluation, and publishing across multiple platforms (LinkedIn, X/Twitter, Blog).

### Core Components

```mermaid
graph TB
    Client[Frontend Client] --> API[FastAPI REST API]
    API --> Services[Business Services]
    Services --> LangGraph[LangGraph Workflow Engine]
    Services --> DB[(PostgreSQL)]
    LangGraph --> AI[OpenAI GPT-4]
    LangGraph --> Search[Tavily Search]
    LangGraph --> Checkpointer[(LangGraph Checkpointer)]
    Services --> Workers[Background Workers]
    Workers --> Publishers[Platform Publishers]
    Publishers --> Platforms[LinkedIn/X/Blog APIs]
```

### Key Technologies

- **FastAPI** - Modern async web framework
- **LangGraph** - Stateful AI workflow orchestration with checkpointing
- **PostgreSQL** - Primary database + LangGraph state persistence
- **SQLAlchemy 2.0** - Async ORM
- **OpenAI GPT-4** - Content generation and evaluation
- **Dramatiq + Redis** - Background job processing
- **Alembic** - Database migrations

---

## üìÅ Project Structure

```
Backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/              # REST API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py          # Authentication (login/signup)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ create.py        # Start new workflows
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workflow.py      # Get workflow status
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ review.py        # Accept/reject drafts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ publish.py       # Publish approved content
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ langgraph/           # LangGraph workflow engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py         # Main workflow graph (fan-out/fan-in)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ platform_subgraph.py  # Per-platform processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py         # State definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ runner.py        # Graph execution runner
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes/           # Workflow nodes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate.py  # AI content generation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py  # AI evaluation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ regenerate.py # Regeneration with feedback
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hitl.py      # Human-in-the-loop pause
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ route.py     # Conditional routing logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/              # AI integrations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator.py # OpenAI content generation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py # OpenAI evaluation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ content_builder.py # Context preparation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ persistence/     # State persistence
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ draft_persister.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/              # SQLAlchemy ORM models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py          # User accounts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workflow.py      # Workflow metadata
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ platform_state.py # Platform-specific state
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ draft.py         # Generated drafts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py    # Evaluation results
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resource.py      # User resources (style samples)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ publishing_job.py # Publishing jobs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workflow_service.py    # Workflow orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ review_service.py      # Draft review logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ publishing_service.py  # Publishing coordination
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ platform_publisher.py  # Platform API integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resource_service.py    # Resource management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth_service.py        # Authentication
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic request/response models
‚îÇ   ‚îú‚îÄ‚îÄ workers/             # Background workers (Dramatiq)
‚îÇ   ‚îú‚îÄ‚îÄ core/                # Core utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py      # JWT authentication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py       # Logging setup
‚îÇ   ‚îú‚îÄ‚îÄ db/                  # Database configuration
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # FastAPI application entry point
‚îÇ
‚îú‚îÄ‚îÄ alembic/                 # Database migrations
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ .env.example             # Environment variables template
‚îî‚îÄ‚îÄ README.md                # This file
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL 14+
- Redis 6+
- OpenAI API key
- (Optional) Tavily API key for web search

### 1. Clone and Setup

```bash
cd Backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment

Copy `.env.example` to `.env` and configure:

```bash
cp .env.example .env
```

**Required variables:**

```env
# Database
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/morphpost

# JWT
JWT_SECRET_KEY=your-secret-key-min-32-chars

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# OpenAI
OPENAI_API_KEY=sk-your-key-here
LLM_MODEL=gpt-4-turbo-preview

# Tavily (optional)
TAVILY_API_KEY=your-tavily-key
```

### 3. Database Setup

```bash
# Create database
createdb morphpost

# Run migrations
alembic upgrade head
```

### 4. Run the Server

```bash
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```

API will be available at: `http://localhost:8000`

Interactive docs: `http://localhost:8000/docs` (development only)

### 5. Run Background Workers (Optional)

For scheduled publishing:

```bash
dramatiq src.workers.publisher
```

---

## üîÑ LangGraph Workflow

### Workflow Architecture

MorphPost uses a **fan-out/fan-in** architecture to process multiple platforms in parallel:

```mermaid
graph LR
    Start([START]) --> Fanout[Fanout Node]
    Fanout -->|Send| P1[Platform: LinkedIn]
    Fanout -->|Send| P2[Platform: X]
    Fanout -->|Send| P3[Platform: Blog]
    P1 --> Merge[Merge Results]
    P2 --> Merge
    P3 --> Merge
    Merge --> Check{All Complete?}
    Check -->|Yes| End([END])
    Check -->|No| Fanout
```

### Platform Subgraph (per platform)

Each platform runs this workflow independently:

```mermaid
graph TD
    Start([START]) --> Generate[Generate Draft]
    Generate --> Evaluate[Evaluate Draft]
    Evaluate --> Route{Score >= 70?}
    Route -->|Yes| HITL[Human Review]
    Route -->|No, Retries Left| Regenerate[Regenerate with Feedback]
    Route -->|No, Max Retries| HITL
    Regenerate --> Generate
    HITL --> End([END])
```

### State Persistence

- **LangGraph Checkpointer**: Stores workflow state in PostgreSQL
- **Enables**: Resume workflows, handle interruptions, human-in-the-loop
- **Thread ID**: Each workflow has a unique thread ID for state isolation

---

## üì° API Endpoints

### Authentication

#### `POST /api/v1/auth/signup`
Create a new user account.

**Request:**
```json
{
  "username": "johndoe",
  "email": "john@example.com",
  "password": "securepassword"
}
```

**Response:**
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "token_type": "bearer"
}
```

#### `POST /api/v1/auth/login`
Authenticate and get access token.

**Request:**
```json
{
  "email": "john@example.com",
  "password": "securepassword"
}
```

---

### Workflow Creation

#### `POST /api/v1/create`
Start a new content creation workflow.

**Headers:**
```
Authorization: Bearer <token>
```

**Request:**
```json
{
  "mode": "manual",
  "platforms": ["linkedin", "x", "blog"],
  "source_content": "AI is transforming software development...",
  "resources": [
    {
      "type": "style_sample",
      "content": "Previous writing sample...",
      "metadata": {}
    }
  ]
}
```

**Response:**
```json
{
  "workflow_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

---

### Workflow Status

#### `GET /api/v1/workflow/{workflow_id}`
Get current workflow status and drafts.

**Response:**
```json
{
  "workflow_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "awaiting_review",
  "created_at": "2026-01-15T19:00:00Z",
  "platforms": [
    {
      "platform": "linkedin",
      "status": "awaiting_review",
      "active_draft": {
        "id": "draft-123",
        "content": "AI is revolutionizing...",
        "source": "ai",
        "created_at": "2026-01-15T19:01:00Z"
      }
    }
  ]
}
```

---

### Review & Approval

#### `POST /api/v1/review/accept`
Accept a draft for publishing.

**Request:**
```json
{
  "workflow_id": "550e8400-e29b-41d4-a716-446655440000",
  "platform": "linkedin"
}
```

#### `POST /api/v1/review/reject`
Reject a draft and regenerate.

**Request:**
```json
{
  "workflow_id": "550e8400-e29b-41d4-a716-446655440000",
  "platform": "linkedin",
  "feedback": "Too technical, make it more conversational"
}
```

---

### Publishing

#### `POST /api/v1/publish`
Publish approved content to platforms.

**Request:**
```json
{
  "workflow_id": "550e8400-e29b-41d4-a716-446655440000",
  "platforms": ["linkedin", "x"],
  "schedule_time": null  // null = immediate, or ISO timestamp
}
```

---

## üîß Configuration

### LangGraph Settings

```python
# src/core/config.py

langgraph_max_iterations: int = 3
evaluation_score_threshold: int = 70
style_drift_tolerance: float = 0.15
```

- **max_iterations**: Maximum regeneration attempts per platform
- **evaluation_score_threshold**: Minimum AI evaluation score to auto-accept
- **style_drift_tolerance**: Allowed deviation from user's writing style

### LLM Configuration

```python
openai_api_key: str
llm_model: str = "gpt-4-turbo-preview"
llm_temperature: float = 0.7
llm_max_tokens: int = 2000
```

---

## üóÑÔ∏è Database Schema

### Key Models

**Workflow** - Top-level workflow metadata
- `id` (UUID, PK)
- `user_id` (FK ‚Üí User)
- `status` (enum: running, awaiting_review, completed)
- `mode` (enum: manual, template)

**PlatformState** - Per-platform state
- `id` (UUID, PK)
- `workflow_id` (FK ‚Üí Workflow)
- `platform` (enum: linkedin, x, blog)
- `status` (enum: generating, evaluating, awaiting_review, accepted, rejected)
- `active_draft_id` (FK ‚Üí Draft)

**Draft** - Generated content versions
- `id` (UUID, PK)
- `workflow_id` (FK ‚Üí Workflow)
- `platform` (enum)
- `content` (text)
- `source` (enum: ai, human)

**Evaluation** - AI evaluation results
- `id` (UUID, PK)
- `draft_id` (FK ‚Üí Draft)
- `score` (int 0-100)
- `feedback` (text)

---

## üß™ Development

### Running Tests

```bash
pytest
```

### Database Migrations

```bash
# Create new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

### Code Style

```bash
# Format code
black src/

# Lint
pylint src/
```

---

## üö¢ Deployment

### Environment Variables

Ensure all required environment variables are set in production:

- Set `ENVIRONMENT=production`
- Set `DEBUG=false`
- Use strong `JWT_SECRET_KEY`
- Configure production database URL
- Set up Redis for background workers

### Running with Gunicorn

```bash
gunicorn src.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000
```

### Background Workers

```bash
dramatiq src.workers.publisher --processes 4 --threads 8
```

---

## üìö Additional Documentation

- [API Reference](./docs/API.md) - Detailed API documentation
- [LangGraph Guide](./docs/LANGGRAPH.md) - Workflow architecture deep dive
- [Database Schema](./docs/DATABASE.md) - Complete schema documentation
- [Deployment Guide](./docs/DEPLOYMENT.md) - Production deployment guide

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

---

## üìÑ License

MIT License - see LICENSE file for details

---

## üÜò Support

For issues and questions:
- GitHub Issues: [MorphPost Issues](https://github.com/yourusername/morphpost/issues)
- Email: support@morphpost.com
